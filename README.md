# ğŸš€ MCP Host 

## ğŸ¯ é¡¹ç›®åŠŸèƒ½

- æä¾›ç®¡ç† MCP Server é…ç½®çš„å¯è§†åŒ–é¢æ¿ï¼šåœ¨é¡µé¢ä¸­æŸ¥çœ‹/æ–°å¢/ç¼–è¾‘/å¯ç”¨/ç¦ç”¨æœåŠ¡å™¨ä¸å·¥å…·ï¼Œå¹¶æ”¯æŒå¤‡æ³¨ä¸å·¥å…·å¼€å…³ç®¡ç†
- ç®€åŒ–æ™ºèƒ½ä½“å¼€å‘ï¼šç”±MCP Host è´Ÿè´£é€‰æ‹©æœåŠ¡å™¨å¹¶æ‰§è¡ŒçœŸå®å·¥å…·è°ƒç”¨ï¼Œå¼€å‘è€…æ— éœ€æ“å¿ƒå¦‚ä½•è°ƒç”¨MCPå·¥å…·

<div align="center">
  <img src="Photo/1.png" alt="MCPç®¡ç†é¡µé¢" style="max-width: 1000px; width: 100%; height: auto;" />
  <p>MCPç®¡ç†é¡µé¢ï¼šå±•ç¤ºæœåŠ¡å™¨åˆ—è¡¨ã€å¯ç”¨/ç¦ç”¨å¼€å…³ã€åˆ é™¤æŒ‰é’®ä¸è¿›å…¥è®¾ç½®é¡µçš„å…¥å£ã€‚</p>
  
</div>

<div align="center">
  <img src="Photo/2.png" alt="å·¥å…·é¡µé¢" style="max-width: 1000px; width: 100%; height: auto;" />
  <p>å·¥å…·é¡µé¢ï¼šå±•ç¤ºé€‰ä¸­æœåŠ¡å™¨çš„å·¥å…·æ¸…å•ä¸å‚æ•°è¯´æ˜ï¼Œæ”¯æŒæŒ‰å·¥å…·å¯ç”¨/ç¦ç”¨ä»¥åŠå¡«å†™å¹¶ä¿å­˜å¤‡æ³¨ã€‚</p>
  
</div>

<div align="center">
  <img src="Photo/3.png" alt="ç¤ºæ„å›¾" style="max-width: 1000px; width: 100%; height: auto;" />
  <p>é¡¹ç›®æ¶æ„å›¾</p>
  
</div>

## âœˆï¸ ç®¡ç†MCP æœåŠ¡å™¨ä¸å·¥å…·

- å¯åŠ¨ç®¡ç†æœåŠ¡ä¸å‰ç«¯ï¼š`python host_server.py`
- æ‰“å¼€ä¸»é¡µï¼š`http://127.0.0.1:8000/`ï¼Œå³å¯æŸ¥çœ‹æ‰€æœ‰å·²é…ç½®çš„ MCP æœåŠ¡å™¨ã€‚
- é…ç½®æ–‡ä»¶å›ºå®šè·¯å¾„ï¼š`config/mcp_server_config.json`

**è‡ªå®šä¹‰ç«¯å£ä¸åœ°å€**

- é»˜è®¤åœ°å€ä¸ç«¯å£ï¼š`127.0.0.1:8000`
- å‘½ä»¤è¡Œå‚æ•°ï¼š
  - æŒ‡å®šç«¯å£ï¼š`python host_server.py --port 9000`
  - æŒ‡å®šåœ°å€ä¸ç«¯å£ï¼š`python host_server.py --host 0.0.0.0 --port 9000`
- ç¯å¢ƒå˜é‡ï¼ˆä½œä¸ºé»˜è®¤å€¼ï¼‰ï¼š
  - `MCP_HOST_ADDR` æŒ‡å®šç»‘å®šåœ°å€ï¼ˆé»˜è®¤ `127.0.0.1`ï¼‰
  - `MCP_HOST_PORT` æˆ– `PORT` æŒ‡å®šç«¯å£ï¼ˆé»˜è®¤ `8000`ï¼‰
- ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼


## âœ¨ ä½¿ç”¨ MCP Host å¿«é€Ÿå¼€å‘æ™ºèƒ½ä½“
æ‚¨å¯é€šè¿‡MCPHostè½»æ¾è°ƒç”¨MCPå·¥å…·:
```python
from mcp_host import MCPHost  # å¼•å…¥ MCP Host

host = MCPHost()  # 0.åˆå§‹åŒ– Hostï¼ˆèšåˆä¸è·¯ç”±å·¥å…·ï¼‰

tools = host.list_all_tools()  # 1.è¯»å–å¯ç”¨æœåŠ¡å™¨çš„å·¥å…·æ³¨å†Œè¡¨
guide = host.tools_guide(tools)  # 2.ç”Ÿæˆå‚æ•°æŒ‡å—ä¾›å¤§æ¨¡å‹å‚è€ƒ
has_tool, spec = host.detect_tool(content)  # 3.ä»å¤§æ¨¡å‹è¾“å‡ºè§£æ <tool> æŒ‡ä»¤ JSON
tool_result = host.call_tool(spec, formated=True)  # 4.æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ
```

- `list_all_tools`ï¼šè¯»å–æ‰€æœ‰å¯ç”¨æœåŠ¡å™¨çš„å¯ç”¨å·¥å…·ï¼Œå½¢æˆæ³¨å†Œè¡¨ç”¨äºæç¤ºä¸åç»­è°ƒç”¨ã€‚
- `tools_guide`ï¼šä» JSON Schema æå–å‚æ•°è¯´æ˜ï¼Œç”Ÿæˆäººç±»å¯è¯»æŒ‡å—ï¼Œå¼•å¯¼æ¨¡å‹å¡«å‚ã€‚
- `detect_tool`ï¼šä»æ¨¡å‹è¾“å‡ºä¸­æå– `<tool>` æŒ‡ä»¤çš„ JSONï¼Œæœ‰åˆ™è¿›å…¥è°ƒç”¨é“¾ï¼Œæ— åˆ™ç›´æ¥å›å¤ã€‚
- `call_tool`ï¼šæŒ‰å·¥å…·åè‡ªåŠ¨å®šä½æœåŠ¡å™¨å¹¶æ‰§è¡Œï¼Œè¿”å›æ ¼å¼åŒ–çš„ `{name, server, result}` JSONï¼Œä¾›ä¸‹ä¸€è½®æ³¨å…¥ `<tool_result>...</tool_result>`ã€‚

ç¤ºä¾‹ä»£ç 

```python
import os
import json
from dotenv import load_dotenv
from openai import OpenAI
from mcp_host import MCPHost # å¼•å…¥ MCP Host

load_dotenv(override=False)

client = OpenAI(base_url=os.getenv("LLM_BASE_URL"), api_key=os.getenv("LLM_API_KEY"))
model = os.getenv("LLM_MODEL")

host = MCPHost()  # 0.åˆå§‹åŒ– Hostï¼ˆèšåˆä¸è·¯ç”±å·¥å…·ï¼‰
tools = host.list_all_tools()  # 1.è¯»å–å¯ç”¨æœåŠ¡å™¨çš„å·¥å…·æ³¨å†Œè¡¨
guide = host.tools_guide(tools)  # 2.ç”Ÿæˆå‚æ•°æŒ‡å—ä¾›å¤§æ¨¡å‹å‚è€ƒ

user_msg = input("è¯·è¾“å…¥æ¶ˆæ¯: ").strip()
sys_prompt = (
    "ä½ æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚å¯ä½¿ç”¨ MCP å·¥å…·ã€‚è‹¥éœ€è¦è°ƒç”¨å·¥å…·ï¼Œ"
    "è¯·ä»…è¾“å‡ºå¦‚ä¸‹æ ¼å¼æ–‡æœ¬ï¼š<tool>{\n\t\"type\": \"function\",\n\t\"name\": \"<å·¥å…·å>\",\n\t\"parameters\": {â€¦}\n}</tool>ã€‚"
    "ä»¥ä¸‹ä¸ºå„å·¥å…·çš„ä½¿ç”¨è¯´æ˜ï¼š\n" + guide
)

first = client.chat.completions.create(
    model=model,
    messages=[
        {"role": "system", "content": sys_prompt},
        {"role": "user", "content": user_msg},
    ],
)
content = first.choices[0].message.content or ""

has_tool, spec = host.detect_tool(content)  # 3.ä»å¤§æ¨¡å‹è¾“å‡ºè§£æ <tool> æŒ‡ä»¤ JSON
if has_tool:
    tool_result = host.call_tool(spec, formated=True)  # 4.æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ
    second = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_msg},
            {"role": "assistant", "content": content},
            {"role": "system", "content": "<tool_result>" + tool_result + "</tool_result> è¯·åŸºäºå·¥å…·ç»“æœç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚"},
        ],
    )
    print(second.choices[0].message.content or "")
else:
    print(content)
```

## ğŸ¤– æ¨¡å‹å…¼å®¹æ€§

- æ”¯æŒä»»æ„å…¼å®¹ OpenAI SDK çš„å¤§æ¨¡å‹ä¸æœåŠ¡å•†ï¼šå°† `LLM_BASE_URL`ã€`LLM_API_KEY`ã€`LLM_MODEL` é…ç½®ä¸ºå¯¹åº”å‚å•†çš„ç½‘å…³ä¸æ¨¡å‹å³å¯ä½¿ç”¨ã€‚
- ç¤ºä¾‹ï¼šArk å¹³å° `LLM_BASE_URL=https://ark.cn-beijing.volces.com/api/v3`ï¼›å…¶ä»– OpenAI å…¼å®¹ç½‘å…³ä¹Ÿå¯æŒ‰éœ€æ›¿æ¢ã€‚


## ğŸ› ï¸ ç¯å¢ƒä¸ä¾èµ–

- å®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt`
- Python: `>=3.10`
  - éªŒè¯: `python --version`
- Node.js: `>=18`
  - é¡¹ç›®æ ¹å« `.nvmrc`ï¼ˆå€¼ä¸º `18`ï¼‰ï¼Œä½¿ç”¨ nvm/nvm-windows å¯æ‰§è¡Œ `nvm use 18`
  - éœ€ç¡®ä¿ `npm/npx` åœ¨ `PATH` ä¸­
  - éªŒè¯: `node -v`ã€`npm -v`ã€`npx --version`
- uv/uvxï¼ˆå¯é€‰ï¼Œç”¨äºéƒ¨åˆ† stdio æœåŠ¡å™¨ï¼‰
  - éªŒè¯: `uvx --version`
- Dockerï¼ˆå¦‚ä½¿ç”¨ `github` æœåŠ¡å™¨æ¡ç›®ï¼‰
  - å½“å‰é…ç½®é€šè¿‡ `docker run -i --rm -e GITHUB_PERSONAL_ACCESS_TOKEN mcp/github` å¯åŠ¨ï¼Œè¯¥æ¡ç›®éœ€è¦æœ¬æœºå®‰è£…å¹¶å¯ç”¨çš„ Docker
  - éªŒè¯: `docker --version`

## ğŸ§ª ç¤ºä¾‹ Demo

- `demo_agent.py`ï¼šåªæ”¯æŒå•æ¬¡è°ƒç”¨å·¥å…·ã€‚
- `demo_agent_multi.py`ï¼šæ”¯æŒå¤šè½®æ¬¡å·¥å…·è°ƒç”¨ï¼Œå¯è¿ç»­å¯¹è¯ï¼ˆæ³¨æ„ï¼šç”¨æˆ·æ¯æ¬¡è¾“å…¥æ–°é—®é¢˜åï¼Œä¸Šä¸‹æ–‡çª—å£éƒ½ä¼šé‡ç½®ï¼Œå³æ™ºèƒ½ä½“ä¸ä¼šè®°å¿†ä¹‹å‰çš„å¯¹è¯ï¼‰ã€‚

è¿è¡Œå‰å‡†å¤‡ï¼š
- å¯åŠ¨ç®¡ç†æœåŠ¡ï¼š`python host_server.py`ï¼ˆæˆ–æŒ‡å®šç«¯å£ï¼š`python host_server.py --port 9000`ï¼‰
- åœ¨ `config/mcp_server_config.json` ä¸­ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå¯ç”¨çš„æœåŠ¡å™¨
- è®¾ç½®æ¨¡å‹ç¯å¢ƒå˜é‡ï¼š`LLM_BASE_URL`ã€`LLM_API_KEY`ã€`LLM_MODEL`

è¿è¡Œç¤ºä¾‹ï¼š
- å•æ¬¡è°ƒç”¨é“¾ï¼š`python demo_agent.py`
- å¤šæ­¥äº¤äº’ï¼š`python demo_agent_multi.py`

